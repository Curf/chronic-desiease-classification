{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD PCA DATA AND Y_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "TRAIN_PCA_X = np.load('./data/TRAIN_PCA.npy')\n",
    "TRAIN_FULL_X = np.load('./data/TRAIN_FULL.npy')\n",
    "TEST_PCA_X = np.load('./data/TEST_PCA.npy')\n",
    "TEST_FULL_X = np.load('./data/TEST_FULL.npy')\n",
    "\n",
    "train_Y = np.load('./data/TRAIN_Y.npy')\n",
    "test_y = np.load('./data/TEST_Y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimensions=TRAIN_PCA_X.shape[1]\n",
    "output_dimensions=train_Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 0.5288483974660356, 1: 9.16599263596306},\n",
       " {0: 0.5293276956486881, 1: 9.024365602900101},\n",
       " {0: 0.5211314007639221, 1: 12.330734876167275},\n",
       " {0: 0.5790125904629722, 1: 3.66405269761606},\n",
       " {0: 0.5518856781499747, 1: 5.31828529401464},\n",
       " {0: 0.5539775421904756, 1: 5.131555825898892},\n",
       " {0: 0.543856884479702, 1: 6.200359315666979},\n",
       " {0: 0.7385379329128022, 1: 1.5480513390354051},\n",
       " {0: 0.6219150591800795, 1: 2.5506080354743346},\n",
       " {0: 0.5197045768007913, 1: 13.187407729049067}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight=[]\n",
    "for i, col in enumerate(train_Y.T):\n",
    "    neg=len(col[col==0])\n",
    "    pos=len(col[col==1])\n",
    "    total=pos+neg\n",
    "    weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "    weight_for_1 = (1 / pos)*(total)/2.0\n",
    "    class_weight.append({0: weight_for_0, 1: weight_for_1})\n",
    "#class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prelim_model_multi(input_dimensions, optimizer = 'adam', k_initializer = 'glorot_uniform', hidden_1_neurons = 512, output_units = output_dimensions, out_activation = 'sigmoid'):\n",
    "    prelim_model_i = Sequential()\n",
    "    prelim_model_i.add(Dense(hidden_1_neurons, input_shape=(input_dimensions,), activation = 'relu', kernel_initializer=k_initializer))\n",
    "    prelim_model_i.add(Dense(10, activation = 'sigmoid'))\n",
    "    prelim_model_i.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return prelim_model_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "303706/303706 [==============================] - 5s 15us/step - loss: 0.2224\n",
      "Epoch 2/15\n",
      "303706/303706 [==============================] - 3s 8us/step - loss: 0.1522\n",
      "Epoch 3/15\n",
      "303706/303706 [==============================] - 3s 9us/step - loss: 0.1482\n",
      "Epoch 4/15\n",
      "303706/303706 [==============================] - 3s 10us/step - loss: 0.1461\n",
      "Epoch 5/15\n",
      "303706/303706 [==============================] - 3s 9us/step - loss: 0.1449\n",
      "Epoch 6/15\n",
      "303706/303706 [==============================] - 3s 8us/step - loss: 0.1441\n",
      "Epoch 7/15\n",
      "303706/303706 [==============================] - 3s 9us/step - loss: 0.1434\n",
      "Epoch 8/15\n",
      "303706/303706 [==============================] - 3s 9us/step - loss: 0.1429\n",
      "Epoch 9/15\n",
      "303706/303706 [==============================] - 3s 9us/step - loss: 0.1425\n",
      "Epoch 10/15\n",
      "303706/303706 [==============================] - 3s 9us/step - loss: 0.1422\n",
      "Epoch 11/15\n",
      "303706/303706 [==============================] - 3s 9us/step - loss: 0.1418\n",
      "Epoch 12/15\n",
      "303706/303706 [==============================] - 3s 9us/step - loss: 0.1415\n",
      "Epoch 13/15\n",
      "303706/303706 [==============================] - 3s 11us/step - loss: 0.1413\n",
      "Epoch 14/15\n",
      "303706/303706 [==============================] - 3s 10us/step - loss: 0.1411\n",
      "Epoch 15/15\n",
      "303706/303706 [==============================] - 3s 9us/step - loss: 0.1409\n"
     ]
    }
   ],
   "source": [
    "model_i = prelim_model_multi(hidden_1_neurons=100, input_dimensions=TRAIN_PCA_X.shape[1])\n",
    "model_i.fit(TRAIN_PCA_X, train_Y, epochs=15, batch_size=1000, verbose=1, class_weight=class_weight)\n",
    "predicted_output = model_i.predict(TEST_PCA_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_conf(true, predict):\n",
    "    confusion_dict={'TP':0, 'TN':0, 'FP':0, 'FN':0}\n",
    "    conf_per_class=[{'TP':0, 'TN':0, 'FP':0, 'FN':0} for class_n in range(true.shape[1])]\n",
    "    for true_i, predict_j in zip(true, predict):\n",
    "\n",
    "        for class_i, (i, j) in enumerate(zip(true_i, predict_j)):\n",
    "\n",
    "            if i==1 and j==1:\n",
    "                conf_per_class[class_i]['TP']+=1\n",
    "            elif i==0 and j==0:\n",
    "                conf_per_class[class_i]['TN']+=1\n",
    "\n",
    "            elif i==1 and j==0:\n",
    "                conf_per_class[class_i]['FN']+=1\n",
    "            elif i==0 and j==1:\n",
    "                conf_per_class[class_i]['FP']+=1        \n",
    "    return(conf_per_class)\n",
    "\n",
    "def my_metrics(y_true, y_pred):\n",
    "    conf=my_conf(y_true, y_pred)\n",
    "    sens=[]\n",
    "    spec=[]\n",
    "    for conditions in conf:\n",
    "        sens.append(conditions['TP']/(conditions['TP']+conditions['FN']))\n",
    "        spec.append(conditions['TN']/(conditions['TN']+conditions['FP']))\n",
    "    print(f'SENSITIVITY PER LABEL: {sens}\\n')\n",
    "    print(f'SPECIFICITY PER LABEL: {spec}\\n')\n",
    "    return(sens, spec)\n",
    "\n",
    "## calculate the mean value of each label predicted and label the value as 1 if it is greater than that mean and 0 otherwise\n",
    "def my_multi_label_acc(y_true, predictions):\n",
    "    class_label_mean={}\n",
    "    for i, class_label in enumerate(predictions.T):\n",
    "        class_label_mean[i]=np.mean(class_label)\n",
    "        \n",
    "    lst=[[] for i in class_label_mean]\n",
    "    for class_label_i in class_label_mean:\n",
    "        for label in predictions.T[class_label_i]:\n",
    "            if label >= class_label_mean[class_label_i]:\n",
    "                lst[class_label_i].append(1)\n",
    "            else:\n",
    "                lst[class_label_i].append(0)\n",
    "    return(np.array(lst).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENSITIVITY PER LABEL: [0.4342068188222034, 0.5472622881949307, 0.523037875829754, 0.16899355200448557, 0.6340067064692892, 0.6068883610451307, 0.5411742096665706, 0.6088765931285617, 0.4603462554718618, 0.5673253208392748]\n",
      "\n",
      "SPECIFICITY PER LABEL: [0.879541373117834, 0.8859941472931231, 0.7291165156471181, 0.7838879689475278, 0.7053097495209185, 0.6493010354714926, 0.7246772550394976, 0.7545464891316718, 0.6303576199381703, 0.6960527576405966]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out=my_multi_label_acc(test_y, predicted_output)\n",
    "mm=my_metrics(test_y, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL HAMMING LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28072387274221927"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(test_y, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
